[{"authors":null,"categories":null,"content":" Coin-changing (Knapsack problem) Solved as an integer programming problem So a friend of mine was interviewing for a semi-software focused position which had also a time-restricted technical test.\nOne of the questions asked was something along these lines:\nA vending machine has been recently installed in your work floor! Unfortunately, there is a limit in the number of bills it can hold, so the technicians would like a way to give out the minimum amount of change in bills needed. So, your task is the following: Write a program that given an initial amount of money (the change to be returned), find the minimum number of bills (of certain denominaions) that add up to it. Our machine can give back only bills of 1,2,5 and 10$!  Pretty straightforward question that many CS students have already seen during their Algorithms101 or CS101 classes.\nIt was also featured in xkcd: This problem is essentialy a variation of a Knapsack Problem. This is a more relevant lemma but there is an unlimited amount of blogs, posts etc on this matter, so I won\u0026rsquo;t delve much on the techincal details.\nI was once again intrigued by it trying to come-up with a fast solution. Although, I knew that Dynamic Programming was the way to go with this problem, my skills regarding classical CS and algos are a bit rusty, so it would take me some time to remember the inner-workings of the approach.. (P.S.: I should head over to GFG to strech out my CS skills)\nThus, I opted for an optimization approach. As, we would like to minimize the number of bills given back, the obvious choice would be an Integer Programming approach, as the count of each denomination will be non-negative integers.\nLet:\n $w \\in \\mathbb{Z}^N$, be the array with the $N$ available denominations $X \\in \\mathbb{Z}^N$, be the count of each denomination returned $C \\in \\mathbb{Z}$, be the wanted amount of cash to be returned  The problem formulation would be :\n$$ min\\sum{X}$$\nwith the restraints:\n $x \u0026gt;= 0, \\forall x \\in X$ (we need a non-negative amount of each denomination) $Χ\\cdot w^Τ = C$ (they must sum up to the needed cash)  That\u0026rsquo;s it. We have formulated the problems and the constraints and we just need the appropriate solver to run the procedure. For my approach python 3 is used.\nWe will rely on the cvxopt package.\nWe will also need the GPLK support for the solver. Check out the docs on how to do so\ndef solve_with_ip(denominations, CASH): \u0026quot;\u0026quot;\u0026quot; Input: - denominations: iterable, a list/array/iterable with the available integer denominations - CASH: int, the needed amount of cash Output: - if the minimization is feasible, a dictionary is returned with keys each denomination and values their corresponding count \u0026quot;\u0026quot;\u0026quot; import cvxpy as cp # The available coin denominations e.g. a 2-dollar bill, a 5-dollar bill and a 10-dollar bill. w = cp.Constant(denominations) # The initial cash to be changed CASH = cp.Constant(CASH) # Variables containing the number of the coins to be returned for each denominator # The size of this must be equal to the denominatios w x = cp.Variable((1, w.shape[0]), integer=True) # We want to minimize the total number of coins returned objective = cp.Minimize(cp.sum(x)) # The constraints constraints = [ w@x.T == CASH, # x\u0026gt;=0 # semi-positive coins ] # Form and solve problem. prob = cp.Problem(objective, constraints) # Need the GLPK_MI solver because the ECOS_BB is not working correctly. prob.solve(solver = 'GLPK_MI') # Returns the optimal value. if prob.status == 'infeasible': print(\u0026quot;Can't change %s with denominations: %s\u0026quot;%(CASH.__str__(), w.__str__())) return -1 else: #return print(\u0026quot;Initial cash %s is changed into %d coins as follows:\u0026quot;%(CASH.__str__(), prob.value)) res = dict(zip([w_ for w_ in w.value], x.value.flatten())) print(res) return res denominations = [1, 2, 5, 10] CASH = 100 _ = solve_with_ip(denominations, CASH)  Competition Let\u0026rsquo;s see how it plays out against two simple strategies found on GeeksforGeeks\nimport sys def solve_with_greedy(denominations, CASH): \u0026quot;\u0026quot;\u0026quot; Greedy approach !! THIS APPROACH DOES NOT RETURN CORRECT RESULTS !! FOR EXAMPLE IF WE HAVE denominations [2,5,10] !! AND WE ASK FOR CASH = 6 THE RESULT WOULD BE !! ONE 5 BILL AND NOTHING ELSE \u0026quot;\u0026quot;\u0026quot; n = len(denominations) # Initialize Result ans = [] # Traverse through all denomination i = n - 1 while(i \u0026gt;= 0): # Find denominations while (CASH \u0026gt;= denominations[i]): CASH -= denominations[i] ans.append(denominations[i]) i -= 1 return ans def solve_with_re(denominations, CASH): \u0026quot;\u0026quot;\u0026quot; Recursive approach \u0026quot;\u0026quot;\u0026quot; m = len(denominations) # base case if (CASH == 0): return 0 # Initialize result res = sys.maxsize # Try every coin that has smaller value than V for i in range(0, m): if (denominations[i] \u0026lt;= CASH): sub_res = solve_with_re(denominations, CASH - denominations[i]) # Check for INT_MAX to avoid overflow and see if # result can minimized if (sub_res != sys.maxsize and sub_res + 1 \u0026lt; res): res = sub_res + 1 return res def solve_with_dp(denominations, CASH): \u0026quot;\u0026quot;\u0026quot; DP_approach \u0026quot;\u0026quot;\u0026quot; m = len(denominations) # table[i] will be storing the minimum # number of coins required for i value. # So table[V] will have result table = [0 for i in range(CASH + 1)] # Base case (If given value V is 0) table[0] = 0 # Initialize all table values as Infinite for i in range(1, CASH + 1): table[i] = sys.maxsize # Compute minimum coins required # for all values from 1 to V for i in range(1, CASH + 1): # Go through all coins smaller than i for j in range(m): if (denominations[j] \u0026lt;= i): sub_res = table[i - denominations[j]] if (sub_res != sys.maxsize and sub_res + 1 \u0026lt; table[i]): table[i] = sub_res + 1 return table[CASH]  print(solve_with_re(denominations, 15)) print(solve_with_greedy(denominations, 15)) print(solve_with_dp(denominations, 15))  Ok, so everything is working as it should. Let\u0026rsquo;s run a test-suite and see how this goes\nimport pandas as pd from time import time import numpy as np methods_names = [\u0026quot;IP\u0026quot;, \u0026quot;DP\u0026quot;, \u0026quot;RE\u0026quot;] methods = [solve_with_ip, solve_with_dp, solve_with_re] test_instances = [1, 10, 51, 101, 501, 1001] #np.random.randint(11, 10000, size=10000) denominations = [1, 2, 5, 10] logs = [] for name, method in zip(methods_names, methods): t_s1 = time() for CASH in test_instances: t_s = time() _ = method(denominations, CASH) logs.append({\u0026quot;Method\u0026quot;:name, \u0026quot;Test\u0026quot;:CASH, \u0026quot;Time\u0026quot;:time()-t_s}) print(\u0026quot;%s finished all tests in %0.2f seconds!\u0026quot;%(name, time()-t_s1))  import seaborn as sns; import matplotlib.pyplot as plt import matplotlib %matplotlib inline df = pd.DataFrame(logs) fig = plt.figure(figsize=(16,5)) SMALL_SIZE = 18 matplotlib.rc('font', size=SMALL_SIZE) matplotlib.rc('axes', titlesize=SMALL_SIZE) sns.lineplot(x='Test', y='Time', hue='Method', data=df) plt.xlabel(\u0026quot;Cash to be returned\u0026quot;) plt.title(\u0026quot;Comparison of Different Methods\u0026quot;) plt.show()  Well as expected the RE method is by far the slowest one. In fact it was so slow, I had to interrupt it from running for all test cases. So, we won\u0026rsquo;t focus on this one.\nRegarding the two main-contesters we can see than the DP one seems to be faster and not really affected by the amount of cash to be returned. We can see a hint of linear dependence to the cash to be returned but this is more of a guess/intuition rather than an insight gained from the graph.\nThis is somewhat expected as Dynamic Programming works really well when the states table is small. This happens because the states that have to be visited are small in number and it can be easy to navigate through them to find the optimal solution,\nOn the other hand, the IP method seems to take up some time for the initial small values, but then the time needed seems constant regardless the value of the cash. However, this constant plateau is still higher than the time needed for the DP method.\nBut what happens, when we change the scale of things?\nLet\u0026rsquo;s run another test suite with much larger values and evaluate the results between the DP and IP method.\nimport pandas as pd from time import time import numpy as np methods_names = [\u0026quot;IP\u0026quot;, \u0026quot;DP\u0026quot;] methods = [solve_with_ip, solve_with_dp] test_instances = np.arange(1000000, step=1000) denominations = [1, 2, 5, 10] logs = [] for name, method in zip(methods_names, methods): t_s1 = time() for CASH in test_instances: t_s = time() _ = method(denominations, CASH) logs.append({\u0026quot;Method\u0026quot;:name, \u0026quot;Test\u0026quot;:CASH, \u0026quot;Time\u0026quot;:time()-t_s}) print(\u0026quot;%s finished all tests in %0.2f seconds!\u0026quot;%(name, time()-t_s1))  import seaborn as sns; import matplotlib.pyplot as plt import matplotlib %matplotlib inline df = pd.DataFrame(logs) fig = plt.figure(figsize=(16,5)) SMALL_SIZE = 18 matplotlib.rc('font', size=SMALL_SIZE) matplotlib.rc('axes', titlesize=SMALL_SIZE) sns.lineplot(x='Test', y='Time', hue='Method', data=df) plt.xlabel(\u0026quot;Cash to be returned\u0026quot;) plt.ylabel(\u0026quot;Time in seconds\u0026quot;) plt.title(\u0026quot;Comparison of DP and IP Methods\u0026quot;) plt.show()  Aha!\nAs we can see the roles have drastically changed.\nThis is expected as the overall time needed for DP based approach would be something along along the lines of:\nNumber-of-states $\\times$ evaluation-time-per-state\nWith constant evaluation time per state, as we increase the possible number of states (the value to be returned) we see a linear increase to the time needed.\nOn the other hand, the IP approach does not suffer from such issues. We see a constant time of less than 0.1 seconds no matter the value of cash needed.\nThis is mainly because of the solver GNU Linear Programming Kit- GLPK whic is optimized for large scale linear problems.\nConclusion So a few final words regarding this post.\nWe visited the problem of Coin-Changing and formulated it as an Integer Programming problem. We evaluated a solver on this problem, alongside some classic recursive and dynamic programming procedures. Finally, we performed the two tests, on different scales of input to benchmark the approaches in a simple way.\nThe analysis done here is by no means perfect. I am sure there are more efficient implementations for both the IP and DP approaches presented here, but this was more of a proof-of-concept and thought provoking experimenation rather than a complete benchmark.\nI hope to have some more time to check the initial performance bump of the IP method (for values of CASH \u0026lt; 200) that seems rather unnatural to me.\nAs a tl;dr closing remarks I would state the following:\n If you\u0026rsquo;d like you could formulate the coin-change problem as an IP problem. This is an approach I have not yet seen, although to me seems very natural. Is it worth the effort? Firstly, the effort in terms of line of code is not so big, as you\u0026rsquo;ve already seen. Secondly, regarding the results, if the coin-change machine in your workplace is expected to give out change in the scale of \u0026gt; 10000$, then it is crucial. If not, don\u0026rsquo;t bother with it. With regards to the interview itself, I think it would be funny to see the reaction of the technical supervisor when confronted with this kind of solution/approach. I would give a (+) to the candidate for the originality of the approach though. Finally, as a note to self, do not forget to brush-up your knowledge on simple CS/Algo problems before heading in a technical interview.  If you have any comments or spot any mistakes/error, feel free to contact me or leave a comment!\n","date":1568926800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568926800,"objectID":"1ff9a686094caca9f420ebfccc6ae77b","permalink":"https://kbogas.github.io/post/coin_change/","publishdate":"2019-09-20T00:00:00+03:00","relpermalink":"/post/coin_change/","section":"post","summary":"Visiting Coin Change as an Integer-Programming problem","tags":["General","CS"],"title":"Coin Change","type":"post"},{"authors":null,"categories":null,"content":"Visit Project\u0026rsquo;s Website\nPrecision medicine promises to transform the delivery of healthcare to patients. Healthcare is evolving from a reactive “one-size-fits-all” system towards a system of predictive, preventive, and precision care. A personalised medicine approach is expected to lead to better health outcomes, improved treatments, and reduction in toxicity due to variable or adverse drug responses.\nThe goal of Project IASIS is to seize the opportunity provided by a wave of data heading our way and turn this into actionable information that would match the right treatment with the right type of patient. A current challenge is that there are large, heterogeneous sets of data ranging from different sources, which if combined would enable the best decisions to be made, allowing for diagnosis and treatment to be personalised to each individual. IASIS is testing this approach in two disease areas – lung cancer and Alzheimer’s disease – but with the longer-term ambition that this approach will be more widely applicable to other disease areas.\n","date":1556312400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556312400,"objectID":"dc473050f42519f45f816eb4af559260","permalink":"https://kbogas.github.io/project/iasis/","publishdate":"2019-04-27T00:00:00+03:00","relpermalink":"/project/iasis/","section":"project","summary":"Research and development for the Knowledge Graph and QA component [2017 - present]","tags":["Biomedical","Graph","Machine Learning","NLP"],"title":"IASIS - Big Data to Support Precision Medicine and Public Health Policy","type":"project"},{"authors":["A. Nentidis, Konstantinos Bougiatiotis, Anastasia Krithara","G. Paliouras"],"categories":null,"content":"","date":1533772800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1533772800,"objectID":"5ded7994cec1846b33eb7a9ba0a926b6","permalink":"https://kbogas.github.io/publication/eccb2018/","publishdate":"2018-08-09T00:00:00Z","relpermalink":"/publication/eccb2018/","section":"publication","summary":"","tags":["NLP","Machine Learning","Graph"],"title":"Semantic integration of disease-specific knowledge","type":"publication"},{"authors":["V. Rentoumi, George Paliouras, Konstantinos Bougiatiotis, Dimitra Arfani, Katerina Fragkopoulou, Spyridoula Varlokosta","P. Garrard"],"categories":null,"content":"","date":1532390400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532390400,"objectID":"ed73d8a3418ec0058ce1d6f94238b18c","permalink":"https://kbogas.github.io/publication/aaic2018/","publishdate":"2018-07-24T00:00:00Z","relpermalink":"/publication/aaic2018/","section":"publication","summary":"","tags":["NLP","Machine Learning"],"title":"Automatic Detection of Linguistic Indicators As a Means of Early Prediction of Alzheimer’s and of Related Dementias: A Cross Linguistics Analysis","type":"publication"},{"authors":null,"categories":null,"content":"Privacy Policy for kbogas.github.io At kbogas.github.io, accessible from kbogas.github.io, one of our main priorities is the privacy of our visitors. This Privacy Policy document contains types of information that is collected and recorded by kbogas.github.io and how we use it.\nIf you have additional questions or require more information about our Privacy Policy, do not hesitate to contact us through email at eystathios.gab@gmail.com\nLog Files kbogas.github.io follows a standard procedure of using log files. These files log visitors when they visit websites. All hosting companies do this and a part of hosting services' analytics. The information collected by log files include internet protocol (IP) addresses, browser type, Internet Service Provider (ISP), date and time stamp, referring/exit pages, and possibly the number of clicks. These are not linked to any information that is personally identifiable. The purpose of the information is for analyzing trends, administering the site, tracking users' movement on the website, and gathering demographic information.\nPrivacy Policies You may consult this list to find the Privacy Policy for each of the advertising partners of kbogas.github.io. Our Privacy Policy was created with the help of the Privacy Policy Generator.\nThird-party ad servers or ad networks uses technologies like cookies, JavaScript, or Web Beacons that are used in their respective advertisements and links that appear on kbogas.github.io, which are sent directly to users' browser. They automatically receive your IP address when this occurs. These technologies are used to measure the effectiveness of their advertising campaigns and/or to personalize the advertising content that you see on websites that you visit.\nNote that kbogas.github.io has no access to or control over these cookies that are used by third-party advertisers.\nThird Party Privacy Policies kbogas.github.io's Privacy Policy does not apply to other advertisers or websites. Thus, we are advising you to consult the respective Privacy Policies of these third-party ad servers for more detailed information. It may include their practices and instructions about how to opt-out of certain options. You may find a complete list of these Privacy Policies and their links here: Privacy Policy Links.\nYou can choose to disable cookies through your individual browser options. To know more detailed information about cookie management with specific web browsers, it can be found at the browsers' respective websites. What Are Cookies?\nChildren's Information Another part of our priority is adding protection for children while using the internet. We encourage parents and guardians to observe, participate in, and/or monitor and guide their online activity.\nkbogas.github.io does not knowingly collect any Personal Identifiable Information from children under the age of 13. If you think that your child provided this kind of information on our website, we strongly encourage you to contact us immediately and we will do our best efforts to promptly remove such information from our records.\nOnline Privacy Policy Only This Privacy Policy applies only to our online activities and is valid for visitors to our website with regards to the information that they shared and/or collect in kbogas.github.io. This policy is not applicable to any information collected offline or via channels other than this website.\nConsent By using our website, you hereby consent to our Privacy Policy and agree to its Terms and Conditions.\n","date":1530133200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530133200,"objectID":"18d05a63a1c8d7ed973cc51838494e41","permalink":"https://kbogas.github.io/privacy/","publishdate":"2018-06-28T00:00:00+03:00","relpermalink":"/privacy/","section":"","summary":"Privacy Policy for kbogas.github.io At kbogas.github.io, accessible from kbogas.github.io, one of our main priorities is the privacy of our visitors. This Privacy Policy document contains types of information that is collected and recorded by kbogas.github.io and how we use it.\nIf you have additional questions or require more information about our Privacy Policy, do not hesitate to contact us through email at eystathios.gab@gmail.com\nLog Files kbogas.github.io follows a standard procedure of using log files.","tags":null,"title":"Privacy Policy","type":"page"},{"authors":null,"categories":null,"content":" Visit BioASQ Challenge Website\nThe Challenge BioASQ organizes challenges on biomedical semantic indexing and question answering (QA). The challenges include tasks relevant to hierarchical text classification, machine learning, information retrieval, QA from texts and structured data, multi-document summarization and many other areas.\nThe BioASQ challenge comprises the following tasks.\nBioASQ Task a on Large-Scale Online Biomedical Semantic Indexing In this task, the participants are asked to classify new PubMed documents, before PubMed curators annotate (in effect, classify) them manually. The classes come from the MeSH hierarchy. As new manual annotations become available, they are used to evaluate the classification performance of participating systems.\nBioASQ Task b on Biomedical Semantic QA (involves IR, QA, summarization and more) This task uses benchmark datasets containing development and test questions, in English, along with gold standard (reference) answers constructed by a team of biomedical experts. The participants have to respond with relevant concepts, articles, snippets and RDF triples, from designated resources, as well as exact and \u0026lsquo;ideal\u0026rsquo; answers.\nBioASQ Task MESINESP on Medical Semantic Indexing in Spanish In this task, the participants are asked to classify new IBECS and LILACS documents, before curators annotate them manually. The classes come from the MeSH hierarchy through the DeCS vocabulary. As new manual annotations become available, they are used to evaluate the classification performance of participating systems.\n","date":1524776400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1524776400,"objectID":"a1f3742843d109ce4ac57713f71346ae","permalink":"https://kbogas.github.io/project/bioasq/","publishdate":"2018-04-27T00:00:00+03:00","relpermalink":"/project/bioasq/","section":"project","summary":"Development (both back- and front-end), user support and maintance of the platform hosting the challenges [2016 - present]","tags":["Biomedical","NLP"],"title":"BioASQ - Large-scale biomedical semantic indexing and question answering competition","type":"project"},{"authors":["Konstantinos Bougiatiotis"],"categories":null,"content":"Just starting out!\n","date":1524171600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538082000,"objectID":"f137c8e2ba03d88f7774f7a8f2ed0995","permalink":"https://kbogas.github.io/post/hello_world/","publishdate":"2018-04-20T00:00:00+03:00","relpermalink":"/post/hello_world/","section":"post","summary":"Created  a simple website and blog for documentations","tags":["General"],"title":"Hello World!","type":"post"},{"authors":["K. Bougiatiotis","T. Giannakopoulos"],"categories":null,"content":"","date":1523750400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1523750400,"objectID":"b145c7f4df8e6240759e58d3303d5894","permalink":"https://kbogas.github.io/publication/bougiatiotis201886/","publishdate":"2018-04-15T00:00:00Z","relpermalink":"/publication/bougiatiotis201886/","section":"publication","summary":"","tags":["Multimedia","Machine Learning","NLP"],"title":"Enhanced movie content similarity based on textual, auditory and visual information","type":"publication"},{"authors":["A. Nentidis","K. Bougiatiotis","A. Krithara","G. Paliouras","I. Kakadiaris"],"categories":null,"content":"","date":1506816000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1506816000,"objectID":"ba4637dddf7b3570e3b80b361aba0e83","permalink":"https://kbogas.github.io/publication/nentidis2018results/","publishdate":"2017-10-01T00:00:00Z","relpermalink":"/publication/nentidis2018results/","section":"publication","summary":"","tags":["Biomedical","Question Answering"],"title":"Results of the sixth edition of the BioASQ Challenge","type":"publication"},{"authors":["A. Nentidis","K. Bougiatiotis","A. Krithara","G. Paliouras","I. Kakadiaris"],"categories":null,"content":"","date":1501804800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1501804800,"objectID":"eeb89943b561cde73a136c480ccf66e9","permalink":"https://kbogas.github.io/publication/nentidis2017results/","publishdate":"2017-08-04T00:00:00Z","relpermalink":"/publication/nentidis2017results/","section":"publication","summary":"","tags":["Biomedical","Question Answering"],"title":"Results of the fifth edition of the BioASQ Challenge","type":"publication"},{"authors":null,"categories":null,"content":" Visit Projects Website\nSocial Media Verification REVEAL aims to advance the necessary technologies for making a higher level analysis of social media possible. The project will enable users to reveal hidden ‘modalities’ such as reputation, influence or credibility of information.at this approach will be more widely applicable to other disease areas.\n","date":1493240400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1493240400,"objectID":"e0de9fed06983257c990f05cc9fbdb9c","permalink":"https://kbogas.github.io/project/reveal/","publishdate":"2017-04-27T00:00:00+03:00","relpermalink":"/project/reveal/","section":"project","summary":"Research and development for Machine Learning [2015 - 2017]","tags":["NLP","Relation Extraction","Graph","Social Networks","Machine Learning"],"title":"REVEAL - Social Media Verification","type":"project"},{"authors":["K. Bougiatiotis and Theodoros Giannakopoulos"],"categories":null,"content":"","date":1463702400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1463702400,"objectID":"ca99415cc04e14570fff57f3d376479d","permalink":"https://kbogas.github.io/publication/setn_bougiatiotisg16/","publishdate":"2016-05-20T00:00:00Z","relpermalink":"/publication/setn_bougiatiotisg16/","section":"publication","summary":"","tags":["NLP","Multimedia","Machine Learning"],"title":"Content Representation and Similarity of Movies based on Topic Extraction from Subtitles","type":"publication"},{"authors":null,"categories":null,"content":" Visit DuchenneMap and join the cause!\nDuchenne Map empowers DMD patients and families to make better healthcare decisions.\nFinding information shouldn’t be hard. Find and structure specialised DMD healthcare in a way that’s best for you. Access disease specific up-to-date information. All in one place.\nPersonalised healthcare journey. Create a personal healthcare journey by visualising options. Eliminate misinformation. Share knowledge and educate yourself.\nVerified DMD information. Follow clinical trials and research projects through every stage. Direct contact with healthcare providers. Know where to find information to make healthcare decisions.\n","date":1461704400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461704400,"objectID":"57a29b3061bd664f6b3ab9e4ece33f9d","permalink":"https://kbogas.github.io/project/duchenemap/","publishdate":"2016-04-27T00:00:00+03:00","relpermalink":"/project/duchenemap/","section":"project","summary":"Project proposal and support (2018-present)","tags":["Biomedical","DMD","Proposal"],"title":"DuchenneMap","type":"project"},{"authors":["K. Bougiatiotis","A. Krithara","G. Paliouras","G. Giannakopoulos"],"categories":null,"content":"","date":1433116800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1433116800,"objectID":"6fd66c192d77af4451b7aec96bd94d4c","permalink":"https://kbogas.github.io/publication/nlpmj16/","publishdate":"2015-06-01T00:00:00Z","relpermalink":"/publication/nlpmj16/","section":"publication","summary":"","tags":["NLP","Machine Learning"],"title":"An exploratory analysis of news trends on twitter","type":"publication"},{"authors":null,"categories":null,"content":" Visit Project\u0026rsquo;s Website\nHolistic Benchmarking of Big Linked Data HOBBIT aims at abolishing the barriers in the adoption and deployment of Big Linked Data by European companies, by means of open benchmarking reports that allow them to assess the fitness of existing solutions for their purposes. These benchmarks are based on data that reflects reality and measures industry-relevant Key Performance Indicators (KPIs) with comparable results using standardized hardware.\n","date":1430082000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1430082000,"objectID":"ab817a297d39db2098dd7efa64e23452","permalink":"https://kbogas.github.io/project/hobbit/","publishdate":"2015-04-27T00:00:00+03:00","relpermalink":"/project/hobbit/","section":"project","summary":"Research and development for the Knowledge Graph [2017 - 2018]","tags":["Graph","Machine Learning"],"title":"HOBBIT - Holistic Benchmarking of Big Linked Data","type":"project"},{"authors":["K. Bougiatiotis and Anastasia Krithara"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"fe4de5be812b80ebf0397fe557883970","permalink":"https://kbogas.github.io/publication/clef_bougiatiotisk16/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/clef_bougiatiotisk16/","section":"publication","summary":"","tags":["NLP","Machine Learning"],"title":"Author Profiling using Complementary Second Order Attributes and Stylometric Features","type":"publication"}]